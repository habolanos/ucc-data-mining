{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1270e4-2f31-4c09-aa6e-9795fd43ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1761/3229016639.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data.csv')\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.2226 - loss: 2.4172 - val_accuracy: 0.2262 - val_loss: 2.3391\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.2263 - loss: 2.3437 - val_accuracy: 0.2230 - val_loss: 2.3389\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.2257 - loss: 2.3397 - val_accuracy: 0.2279 - val_loss: 2.3334\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.2287 - loss: 2.3346 - val_accuracy: 0.2292 - val_loss: 2.3286\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.2302 - loss: 2.3289 - val_accuracy: 0.2289 - val_loss: 2.3264\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.2293 - loss: 2.3268 - val_accuracy: 0.2284 - val_loss: 2.3250\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 8ms/step - accuracy: 0.2280 - loss: 2.3288 - val_accuracy: 0.2298 - val_loss: 2.3277\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.2298 - loss: 2.3275 - val_accuracy: 0.2305 - val_loss: 2.3236\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - accuracy: 0.2302 - loss: 2.3255 - val_accuracy: 0.2306 - val_loss: 2.3238\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.2307 - loss: 2.3261 - val_accuracy: 0.2293 - val_loss: 2.3268\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - accuracy: 0.2296 - loss: 2.3252 - val_accuracy: 0.2305 - val_loss: 2.3224\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7ms/step - accuracy: 0.2304 - loss: 2.3246 - val_accuracy: 0.2302 - val_loss: 2.3228\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.2316 - loss: 2.3216 - val_accuracy: 0.2304 - val_loss: 2.3243\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.2300 - loss: 2.3270 - val_accuracy: 0.2310 - val_loss: 2.3217\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.2302 - loss: 2.3205 - val_accuracy: 0.2296 - val_loss: 2.3228\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.2292 - loss: 2.3254 - val_accuracy: 0.2313 - val_loss: 2.3209\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - accuracy: 0.2333 - loss: 2.3220 - val_accuracy: 0.2311 - val_loss: 2.3210\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 7ms/step - accuracy: 0.2314 - loss: 2.3228 - val_accuracy: 0.2312 - val_loss: 2.3209\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7ms/step - accuracy: 0.2297 - loss: 2.3267 - val_accuracy: 0.2310 - val_loss: 2.3212\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.2306 - loss: 2.3237 - val_accuracy: 0.2289 - val_loss: 2.3229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb5a416cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Preprocesamiento de datos\n",
    "\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "\n",
    "data['HOUR'] = data['DATE OF OCCURRENCE'].dt.hour\n",
    "data['DAY_OF_WEEK'] = data['DATE OF OCCURRENCE'].dt.dayofweek\n",
    "data['MONTH'] = data['DATE OF OCCURRENCE'].dt.month\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['HOUR', 'DAY_OF_WEEK', 'MONTH']].values\n",
    "y = data['DESCRIPTION']\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Construir la red neuronal recurrente (LSTM)\n",
    "model = Sequential([\n",
    " LSTM(64, input_shape=(X_train.shape[1], 1), activation='relu', return_sequences=True),\n",
    " LSTM(32, activation='relu'),\n",
    " Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Ajustar el modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1cf84d-3420-4b80-ad62-abe129e4e564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1761/3376535346.py:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.2189 - loss: 2.4251 - val_accuracy: 0.2205 - val_loss: 2.4019\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.2230 - loss: 2.3646 - val_accuracy: 0.2205 - val_loss: 2.3866\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.2216 - loss: 2.3678 - val_accuracy: 0.2205 - val_loss: 2.3798\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.2232 - loss: 2.3669 - val_accuracy: 0.2205 - val_loss: 2.3885\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.2222 - loss: 2.3638 - val_accuracy: 0.2205 - val_loss: 2.3825\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.2230 - loss: 2.3653 - val_accuracy: 0.2205 - val_loss: 2.3874\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2218 - loss: 2.3671 - val_accuracy: 0.2205 - val_loss: 2.3780\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.2206 - loss: 2.3677 - val_accuracy: 0.2205 - val_loss: 2.3897\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.2217 - loss: 2.3676 - val_accuracy: 0.2205 - val_loss: 2.3837\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.2216 - loss: 2.3682 - val_accuracy: 0.2205 - val_loss: 2.3864\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2232 - loss: 2.3624 - val_accuracy: 0.2205 - val_loss: 2.3835\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2222 - loss: 2.3619 - val_accuracy: 0.2205 - val_loss: 2.3965\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.2234 - loss: 2.3612 - val_accuracy: 0.2205 - val_loss: 2.4078\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2223 - loss: 2.3643 - val_accuracy: 0.2205 - val_loss: 2.3962\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2209 - loss: 2.3656 - val_accuracy: 0.2205 - val_loss: 2.3928\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.2216 - loss: 2.3650 - val_accuracy: 0.2205 - val_loss: 2.3999\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2223 - loss: 2.3601 - val_accuracy: 0.2205 - val_loss: 2.3915\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.2207 - loss: 2.3656 - val_accuracy: 0.2205 - val_loss: 2.4018\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2215 - loss: 2.3612 - val_accuracy: 0.2205 - val_loss: 2.3949\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.2223 - loss: 2.3615 - val_accuracy: 0.2205 - val_loss: 2.4284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb2a102d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "# Asegúrate de que los datos estén ordenados cronológicamente\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "data = data.sort_values(by='DATE OF OCCURRENCE')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['DATE OF OCCURRENCE']].values\n",
    "y = data['DESCRIPTION']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(len(y.unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Ajustar etiquetas:\n",
    "# Convertir las etiquetas a números enteros\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ajustar el modelo\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628a153f-bdca-49fc-bacf-8f51c8d58bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1761/2443243694.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.2121 - loss: 2.4344 - val_accuracy: 0.2205 - val_loss: 2.4087\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.2218 - loss: 2.3669 - val_accuracy: 0.2205 - val_loss: 2.3788\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.2209 - loss: 2.3676 - val_accuracy: 0.2205 - val_loss: 2.3763\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.2218 - loss: 2.3666 - val_accuracy: 0.2205 - val_loss: 2.3787\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2227 - loss: 2.3656 - val_accuracy: 0.2205 - val_loss: 2.3876\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2221 - loss: 2.3657 - val_accuracy: 0.2205 - val_loss: 2.3797\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.2195 - loss: 2.3687 - val_accuracy: 0.2205 - val_loss: 2.3816\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.2231 - loss: 2.3611 - val_accuracy: 0.2205 - val_loss: 2.3763\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2224 - loss: 2.3656 - val_accuracy: 0.2205 - val_loss: 2.3858\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2215 - loss: 2.3667 - val_accuracy: 0.2205 - val_loss: 2.3819\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.2212 - loss: 2.3651 - val_accuracy: 0.2205 - val_loss: 2.3894\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2215 - loss: 2.3627 - val_accuracy: 0.2205 - val_loss: 2.3810\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.2231 - loss: 2.3649 - val_accuracy: 0.2205 - val_loss: 2.3817\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.2213 - loss: 2.3635 - val_accuracy: 0.2205 - val_loss: 2.3897\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.2220 - loss: 2.3629 - val_accuracy: 0.2205 - val_loss: 2.3874\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.2212 - loss: 2.3634 - val_accuracy: 0.2205 - val_loss: 2.3774\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - accuracy: 0.2225 - loss: 2.3617 - val_accuracy: 0.2205 - val_loss: 2.3814\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.2206 - loss: 2.3612 - val_accuracy: 0.2205 - val_loss: 2.3819\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.2230 - loss: 2.3607 - val_accuracy: 0.2205 - val_loss: 2.3863\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.2208 - loss: 2.3654 - val_accuracy: 0.2205 - val_loss: 2.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbaefac2e90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Preprocesamiento de datos\n",
    "# Asegúrate de que los datos estén ordenados cronológicamente\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "data = data.sort_values(by='DATE OF OCCURRENCE')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['DATE OF OCCURRENCE']].values\n",
    "y = data['DESCRIPTION']\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Ajustar las dimensiones para la entrada de ARNN (reshape)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "# Construir la red neuronal auto-recurrente (ARNN)\n",
    "model = Sequential([\n",
    " SimpleRNN(64, activation='relu', return_sequences=True),\n",
    " SimpleRNN(32, activation='relu'),\n",
    " Dense(len(y.unique()), activation='softmax')\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convertir etiquetas de texto a valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ajustar el modelo con las etiquetas numéricas\n",
    "model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Ajustar el modelo\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18a4627-8617-4f64-bac2-06077236ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1761/1475871312.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb57fdc550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['X COORDINATE', 'Y COORDINATE']].values\n",
    "y_latitude = data['LATITUDE'].values\n",
    "y_longitude = data['LONGITUDE'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_lat_train, y_lat_test, y_long_train, y_long_test = train_test_split( X, y_latitude, y_longitude, test_size=0.2, random_state=42)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir la red neuronal profunda (DNN)\n",
    "# Construir la red neuronal profunda (DNN)\n",
    "model_lat = Sequential([\n",
    " Dense(64, activation='relu'),\n",
    " Dense(32, activation='relu'),\n",
    " Dense(1)\n",
    "])\n",
    "\n",
    "model_long = Sequential([\n",
    " Dense(64, activation='relu'),\n",
    " Dense(32, activation='relu'),\n",
    " Dense(1)\n",
    "])\n",
    "# Compilar el modelo\n",
    "model_lat.compile(optimizer='adam', loss='mse')\n",
    "model_long.compile(optimizer='adam', loss='mse')\n",
    "# Ajustar el modelo\n",
    "model_lat.fit(X_train, y_lat_train, epochs=20, batch_size=32, validation_data=(X_test, y_lat_test))\n",
    "model_long.fit(X_train, y_long_train, epochs=20, batch_size=32, validation_data=(X_test, y_long_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e17ae0-a71a-4976-86be-1d793186509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1761/2549059238.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.1105 - loss: 3.8210 - val_accuracy: 0.1179 - val_loss: 3.6642\n",
      "Epoch 2/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.1164 - loss: 3.6707 - val_accuracy: 0.1179 - val_loss: 3.6558\n",
      "Epoch 3/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.1168 - loss: 3.6576 - val_accuracy: 0.1179 - val_loss: 3.6535\n",
      "Epoch 4/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.1185 - loss: 3.6585 - val_accuracy: 0.1179 - val_loss: 3.6517\n",
      "Epoch 5/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.1172 - loss: 3.6581 - val_accuracy: 0.1179 - val_loss: 3.6520\n",
      "Epoch 6/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.1164 - loss: 3.6583 - val_accuracy: 0.1179 - val_loss: 3.6512\n",
      "Epoch 7/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.1164 - loss: 3.6574 - val_accuracy: 0.1179 - val_loss: 3.6519\n",
      "Epoch 8/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.1172 - loss: 3.6536 - val_accuracy: 0.1179 - val_loss: 3.6508\n",
      "Epoch 9/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.1164 - loss: 3.6566 - val_accuracy: 0.1179 - val_loss: 3.6504\n",
      "Epoch 10/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.1174 - loss: 3.6537 - val_accuracy: 0.1179 - val_loss: 3.6532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbae5837f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Eliminar filas con valores nan\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "X_title = data['DESCRIPTION'].values\n",
    "X_location = data['LOCATION'].apply(lambda x: [float(coordinate) for coordinate in x[1:-1].split(', ')])  # Convertir coordenadas en lista de flotantes\n",
    "y = data['SECONDARY DESCRIPTION'].values\n",
    "\n",
    "# Codificar etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Separar datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_location, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar coordenadas geográficas\n",
    "def calculate_distance(coord):\n",
    "    # Supongamos que utilizamos el origen como punto de referencia\n",
    "    reference_point = [0.0, 0.0]\n",
    "    return np.linalg.norm(np.array(coord) - np.array(reference_point))\n",
    "\n",
    "X_train_normalized = np.array([calculate_distance(coord) for coord in X_train]).reshape(-1, 1)\n",
    "X_test_normalized = np.array([calculate_distance(coord) for coord in X_test]).reshape(-1, 1)\n",
    "\n",
    "# Modelo de texto\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar el modelo\n",
    "model.fit(X_train_normalized, y_train, epochs=10, batch_size=32, validation_data=(X_test_normalized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225f479-d012-41c9-8d05-6f0abf9a5a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
